# Development/Production environment

# Database
DATABASE_URL=postgresql://postgres.goflmrvzwagridonyxxn:OjUtCVVtoV0nGPPP@aws-1-us-east-1.pooler.supabase.com:6543/postgres

# Disable tokenizers parallelism warning (happens with forked processes)
TOKENIZERS_PARALLELISM=false

# Main LLM Configuration (for memory operations: put/think/opinions)
# Choose one: "openai", "groq", or "ollama"
MEMORY_LLM_PROVIDER=groq
MEMORY_LLM_API_KEY=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
MEMORY_LLM_MODEL=openai/gpt-oss-120b
# MEMORY_LLM_BASE_URL=http://localhost:11434/v1  # For ollama or custom endpoints

# Judge LLM Configuration (for benchmark evaluation)
# If not set, falls back to main LLM configuration
JUDGE_LLM_PROVIDER=groq
JUDGE_LLM_API_KEY=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
JUDGE_LLM_MODEL=openai/gpt-oss-120b
# JUDGE_LLM_BASE_URL=https://api.custom.com/v1  # Optional custom endpoint
